{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hahaitsriya/FinalYearProject/blob/AI/Data_Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 -Scraping the data from Hamshospital**"
      ],
      "metadata": {
        "id": "r-P-DLMaXzkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_doctors(url_link):\n",
        "    response = requests.get(url_link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    sections = soup.find_all('div', class_=\"featured-content featured-content-team\")\n",
        "    headers = ['name', 'designation', 'position']\n",
        "    # Open a new CSV file in write mode\n",
        "    with open('doctors1.csv', 'a', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        # Write the headers to the CSV file\n",
        "        writer.writerow(headers)\n",
        "\n",
        "        # Iterate over each section and write the data to the CSV file\n",
        "        for section in sections:\n",
        "            doctor_name = section.find('div', class_=\"featured-title\")\n",
        "            doctor_designation = section.find('div', class_=\"team-designation\")\n",
        "            doctor_position = section.find('div', class_=\"team-position\")\n",
        "\n",
        "            # Check if the elements exist and extract text, else use a placeholder\n",
        "            name_text = doctor_name.text.strip() if doctor_name else 'N/A'\n",
        "            designation_text = doctor_designation.text.strip() if doctor_designation else 'N/A'\n",
        "            position_text = doctor_position.text.strip() if doctor_position else 'N/A'\n",
        "\n",
        "            # Write the data as a row in the CSV file\n",
        "            writer.writerow([name_text, designation_text, position_text])\n",
        "\n",
        "# Call the function with the URL as the argument\n",
        "for x in range(8):\n",
        "  url_link = \"https://hamshospital.com/doctors/page/\" + str(x)\n",
        "  scrape_doctors(url_link)"
      ],
      "metadata": {
        "id": "hSLmJED-XxDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2- Scraping the data from the Medicare Hospital**"
      ],
      "metadata": {
        "id": "sWKmiAljYTFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_doctors(url_link):\n",
        "    response = requests.get(url_link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    sections = soup.find_all('div',class_= \"col-lg-3 col-md-6 col-sm-12\")\n",
        "\n",
        "    # Open a new CSV file in write mode\n",
        "    with open('doctors2.csv', 'a', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        # Iterate over each section and write the data to the CSV file\n",
        "        for section in sections:\n",
        "            doctor_name = section.find('div',class_ = \"doc-name\")\n",
        "            doctor_designation = section.find('h3',class_='desgination')\n",
        "\n",
        "            # Check if the elements exist and extract text, else use a placeholder\n",
        "            if doctor_name and doctor_designation is not None:\n",
        "              name_text = doctor_name.text.strip() if doctor_name else 'N/A'\n",
        "              designation_text = doctor_designation.text.strip() if doctor_designation else 'N/A'\n",
        "              # Write the data as a row in the CSV file\n",
        "              writer.writerow([name_text, designation_text])\n",
        "\n",
        "# Call the function with the URL as the argument\n",
        "for x in range(8):\n",
        "  url_link = \"https://medicarehosp.com/doctors?page=\" + str(x)\n",
        "  scrape_doctors(url_link)\n"
      ],
      "metadata": {
        "id": "bXKVKsiSXxGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3- Scraping data of Manipalpokhara Hospital**"
      ],
      "metadata": {
        "id": "z6Nic-aHYZFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_doctors(url_link):\n",
        "    response = requests.get(url_link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    sections = soup.find_all('div',class_=\"faculty-card__content\")\n",
        "\n",
        "    # Open a new CSV file in write mode\n",
        "    with open('doctors3.csv', 'a', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        # Iterate over each section and write the data to the CSV file\n",
        "        for section in sections:\n",
        "            doctor_name = section.find('h3',class_ = \"title\")\n",
        "            doctor_designation = section.find('h4',class_='position')\n",
        "\n",
        "            # Check if the elements exist and extract text, else use a placeholder\n",
        "            if doctor_name and doctor_designation is not None:\n",
        "              name_text = doctor_name.text.strip() if doctor_name else 'N/A'\n",
        "              designation_text = doctor_designation.text.strip() if doctor_designation else 'N/A'\n",
        "\n",
        "              # Write the data as a row in the CSV file\n",
        "              writer.writerow([name_text, designation_text])\n",
        "\n",
        "# Call the function with the URL as the argument\n",
        "url_link = \"https://manipalpokhara.edu.np/academics/faculty/\"\n",
        "scrape_doctors(url_link)\n"
      ],
      "metadata": {
        "id": "PVAJg6qQXxL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}